{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import gb.hypergraph.symbol as sym\n",
    "import gb.hypergraph.edge as ed\n",
    "import gb.nlp.parser as par\n",
    "import gb.tools.json as json_tools\n",
    "from gb.clusters.meronomy import Meronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_PROB = -12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = par.Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "edge_data = json_tools.read('../all.json')\n",
    "\n",
    "# build full edges list\n",
    "full_edges = []\n",
    "for it in edge_data:\n",
    "    full_edges.append(ed.without_namespaces(ed.str2edge(it['edge'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build meronomy\n",
    "mer = Meronomy(parser, full_edges)\n",
    "mer.normalize_graph()\n",
    "\n",
    "# generate synonyms\n",
    "mer.generate_synonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rel_contains(full_edge, term):\n",
    "    if sym.is_edge(full_edge) and len(full_edge) > 2 and sym.is_edge(full_edge[2]):\n",
    "        rel = full_edge[0]\n",
    "        if sym.is_edge(rel):\n",
    "            return term in rel\n",
    "        else:\n",
    "            return rel == term\n",
    "    return False\n",
    "\n",
    "\n",
    "say_edges = []\n",
    "for full_edge in full_edges:\n",
    "    if rel_contains(full_edge, 'says'):\n",
    "        say_edges.append(full_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edge2str(edge):\n",
    "    s = ed.edge2str(edge, namespaces=False)\n",
    "    if sym.is_edge(edge):\n",
    "        return s\n",
    "\n",
    "    if s[0] == '+':\n",
    "        s = s[1:]\n",
    "\n",
    "    if len(s) == 0:\n",
    "        return None\n",
    "\n",
    "    if not s[0].isalnum():\n",
    "        return None\n",
    "\n",
    "    word = parser.make_word(s)\n",
    "    if word.prob < MAX_PROB:\n",
    "        return s\n",
    "\n",
    "    return None\n",
    "\n",
    "def edge2syn(edge):\n",
    "    atom = edge2str(edge)\n",
    "    if atom:\n",
    "        syn_id = mer.syn_id(atom)\n",
    "        if syn_id:\n",
    "            return syn_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(+ donald trump), trump, donald} 358\n",
      "{(+ bernie sanders), bernie, sanders} 93\n",
      "{hillary, (+ hillary clinton), clinton} 88\n",
      "{obama} 75\n",
      "{paul, ryan, (+ paul ryan)} 21\n",
      "{(+ mike pence), pence, mike} 17\n",
      "{(+ john kasich), john, kasich} 15\n",
      "{(+ gary johnson), (+libertarian (+ gary johnson)), johnson} 14\n",
      "{(+the latest)} 14\n",
      "{(+ white house)} 13\n",
      "{(+the fbi), fbi} 11\n",
      "{rubio, marco, (+ marco rubio)} 11\n",
      "{(+ chris christie), chris, christie} 9\n",
      "{(+ bill clinton)} 9\n",
      "{(+ trump campaign)} 9\n",
      "{mitch, (+ mitch mcconnell), mcconnell} 9\n",
      "{giuliani, (+ rudy giuliani), rudy} 8\n",
      "{(+ newt gingrich), gingrich, newt} 8\n",
      "{warren, (+ elizabeth warren), elizabeth} 7\n"
     ]
    }
   ],
   "source": [
    "sayers = {}\n",
    "sayers_and_claims = {}\n",
    "for edge in say_edges:\n",
    "    sayer = edge2syn(edge[1])\n",
    "    if sayer not in sayers_and_claims:\n",
    "        sayers[sayer] = 0\n",
    "        sayers_and_claims[sayer] = []\n",
    "    sayers[sayer] += 1\n",
    "    sayers_and_claims[sayer].append(edge[2])\n",
    "        \n",
    "sorted_sayers = sorted(sayers.items(), key=operator.itemgetter(1), reverse=True)\n",
    "for t in sorted_sayers[:20]:\n",
    "    syn_id = t[0]\n",
    "    if syn_id:\n",
    "        print('%s %s' % (mer.synonym_label(syn_id), t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concepts_by_sayer = {}\n",
    "\n",
    "\n",
    "def add_concepts(targ, src):\n",
    "    for key in src:\n",
    "        if key in targ:\n",
    "            targ[key] += src[key]\n",
    "        else:\n",
    "            targ[key] = src[key]\n",
    "\n",
    "\n",
    "def concepts_in_claim(claim, concept_map=None):\n",
    "    if not concept_map:\n",
    "        concept_map = {}\n",
    "    syn_id = edge2syn(claim)\n",
    "    if syn_id:\n",
    "        if syn_id not in concept_map:\n",
    "            concept_map[syn_id] = 0\n",
    "        concept_map[syn_id] += 1\n",
    "        \n",
    "        if sym.is_edge(claim):\n",
    "            for item in claim:\n",
    "                concepts_in_claim(item, concept_map)\n",
    "    return concept_map\n",
    "\n",
    "\n",
    "def get_concepts_by_sayer(sayer, that_include=None):\n",
    "    concept_map = {}\n",
    "    for claim in sayers_and_claims[sayer]:\n",
    "        claim_concepts = concepts_in_claim(claim)\n",
    "        if not that_include:\n",
    "            add_concepts(concept_map, claim_concepts)\n",
    "        elif that_include in claim_concepts.keys():\n",
    "            del claim_concepts[that_include]\n",
    "            add_concepts(concept_map, claim_concepts)\n",
    "    return concept_map\n",
    "\n",
    "\n",
    "for sayer in sayers_and_claims:\n",
    "    concepts_by_sayer[sayer] = get_concepts_by_sayer(sayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {(+ donald trump), trump, donald} 358 1480\n",
      "8 {sanders, (+ bernie sanders), bernie} 93 369\n",
      "20 {hillary, clinton, (+ hillary clinton)} 88 338\n",
      "258779 {obama} 75 302\n",
      "765 {ryan, paul, (+ paul ryan)} 21 95\n",
      "453 {(+ mike pence), mike, pence} 17 70\n",
      "51 {john, kasich, (+ john kasich)} 15 62\n",
      "1 {johnson, (+ gary johnson), (+libertarian (+ gary johnson))} 14 44\n",
      "265028 {(+the latest)} 14 58\n",
      "259384 {(+ white house)} 13 55\n",
      "152 {fbi, (+the fbi)} 11 39\n",
      "504 {(+ marco rubio), rubio, marco} 11 39\n",
      "724 {(+ chris christie), christie, chris} 9 28\n",
      "265755 {(+ bill clinton)} 9 40\n",
      "260928 {(+ trump campaign)} 9 38\n",
      "843 {(+ mitch mcconnell), mcconnell, mitch} 9 39\n",
      "811 {rudy, giuliani, (+ rudy giuliani)} 8 33\n",
      "234 {gingrich, newt, (+ newt gingrich)} 8 38\n",
      "209 {elizabeth, warren, (+ elizabeth warren)} 7 36\n"
     ]
    }
   ],
   "source": [
    "for t in sorted_sayers[:20]:\n",
    "    syn_id = t[0]\n",
    "    if syn_id:\n",
    "        print('%s %s %s %s' % (syn_id, mer.synonym_label(syn_id), t[1], len(concepts_by_sayer[syn_id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(+ donald trump), trump, donald} 28\n",
      "{(+ bernie sanders), bernie, sanders} 25\n",
      "{(+under (+federal (+for investigation (+her (+of use (+a (+private (+ email server)))))))), (+ email server), (+of use (+a (+private (+ email server)))), (+over (+her (+of use (+a (+private (+ email server)))))), (+federal (+for investigation (+her (+of use (+a (+private (+ email server))))))), (+private (+ email server)), (+for investigation (+her (+of use (+a (+private (+ email server)))))), (+her (+of use (+a (+private (+ email server))))), (+a (+private (+ email server)))} 6\n",
      "{(+' choices), (+hard (+' choices)), (+about (+hard (+' choices))), (+but it (+about (+hard (+' choices))))} 4\n",
      "{homework’, (+ his homework’), (+ bank regulation), (+on (+ his homework’) (+ bank regulation))} 4\n",
      "{(+and paranoia prejudice), prejudice, (+on (+and paranoia prejudice)), paranoia} 4\n",
      "{(+more (+than (+$ 200,000))), (+$ 200,000), (+just (+more (+than (+$ 200,000)))), (+in (+just (+more (+than (+$ 200,000)))) income), 200,000, (+about (+$ 200,000)), (+tickets (+$ 200,000)), (+than (+$ 200,000))} 3\n",
      "{flint, (+in (+the (+flint (+ water crisis)))), (+flint (+ water crisis)), (+ water crisis), (+the (+flint (+ water crisis)))} 3\n",
      "{(+was_careless it), (+believes (+was_careless it)), was_careless} 3\n",
      "{(+the fbi), fbi} 3\n",
      "{(+by (+national (+ news groups))), (+ news groups), (+national (+ news groups))} 3\n",
      "{(+of world fantasy), (+a (+of world fantasy)), (+in (+a (+of world fantasy)))} 3\n",
      "{(+a (+ donor influence) (+ her vote)), (+ donor influence), (+ her vote)} 3\n",
      "{(have (+a (+ record 90%) (+of americans)) (+ health insurance) today), (+ record 90%), (+a (+ record 90%) (+of americans))} 3\n",
      "{rooted_for, (+the housing crisis), (+rooted_for (+the housing crisis))} 3\n",
      "{(+ propaganda videos), (+in (+terrorist (+ propaganda videos))), (+terrorist (+ propaganda videos))} 3\n",
      "{(+his (+ climate denial)), (+ climate denial), (+citing (+his (+ climate denial)))} 3\n",
      "{(+target (+of investigation)), (+of investigation), (is she (+target (+of investigation)))} 3\n",
      "{putin} 3\n",
      "{(+'s (+ sexual past) bill), (+after (+'s (+ sexual past) bill)), (+if go we (+after (+'s (+ sexual past) bill))), (+ sexual past)} 2\n"
     ]
    }
   ],
   "source": [
    "concepts = concepts_by_sayer[20]\n",
    "\n",
    "sorted_concepts = sorted(concepts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "for t in sorted_concepts[:20]:\n",
    "    syn_id = t[0]\n",
    "    if syn_id:\n",
    "        print('%s %s' % (mer.synonym_label(syn_id), t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "258779",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-281d1bff31f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconcepts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcepts_by_sayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconcepts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcepts_by_sayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m258779\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcepts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcepts2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 258779"
     ]
    }
   ],
   "source": [
    "# common concepts\n",
    "\n",
    "concepts1 = set(concepts_by_sayer[2].keys())\n",
    "concepts2 = set(concepts_by_sayer[258779].keys())\n",
    "\n",
    "common = concepts1.intersection(concepts2)\n",
    "for concept in common:\n",
    "    print(mer.synonym_label(concept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(+and (+ bernie sanders) (+a communist))} 1\n",
      "{(+a communist)} 1\n",
      "{(+' sanders)} 2\n",
      "{(will_debate he (+ bernie sanders) (+for (+$ (+10 million))))} 1\n",
      "{(will_debate in), will_debate} 1\n",
      "{(+for (+$ (+10 million)))} 1\n",
      "{(+$ (+10 million)), (+10 million), (+than (+$ (+10 million))), (+more (+than (+$ (+10 million))))} 2\n",
      "{(would_kill (+ bernie sanders) golf (+with high taxes))} 1\n",
      "{(thought would_kill), ((thought would_kill) economists obamacare jobs), would_kill} 1\n",
      "{(+with high taxes)} 1\n",
      "{('ll_order he supporters (+to_disrupt (+rallies (+' sanders))))} 1\n",
      "{(+to_disrupt (+rallies (+' sanders)))} 1\n",
      "{(+ pipeline drilling), (+to_disrupt (+ pipeline drilling)), to_disrupt} 1\n",
      "{(+rallies (+' sanders))} 1\n",
      "{rallies} 1\n",
      "{(+clinton says not_qualified’ because sanders so)} 1\n",
      "{hillary, (+ hillary clinton), clinton} 1\n",
      "{not_qualified’} 1\n",
      "{(says sanders (+no debate) (+ interested networks))} 1\n",
      "{(+no debate)} 1\n",
      "{(+ interested networks)} 1\n",
      "{(sold (+ bernie sanders) (+ his soul) (+to (+the devil’)))} 1\n",
      "{(+ his soul)} 1\n",
      "{(+the devil’), devil’, (+to (+the devil’))} 3\n"
     ]
    }
   ],
   "source": [
    "concepts = get_concepts_by_sayer(2, that_include=8)\n",
    "for concept in concepts:\n",
    "    print('%s %s' % (mer.synonym_label(concept), concepts[concept]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
